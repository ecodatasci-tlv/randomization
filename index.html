<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Randomization and Null Models</title>
    <meta charset="utf-8" />
    <meta name="date" content="2019-03-13" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Randomization and Null Models
## EcoDataSci-TLV
### 2019-03-13

---




# What is randomization

---

# Make your randomization reproducible


```r
set.seed(20180313)
```

--


```r
snacks &lt;- c("pretzels", "cookies", "popcorn", "bamba", "carrots")
sample(snacks, 3)
```

```
## [1] "popcorn" "cookies" "bamba"
```

_If you use the same seed, you should be getting the same results as us!_

---
# Sampling with replacement


```r
sample(snacks, 10)
```

```
## Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'
```

--


```r
sample(snacks, 10, replace = TRUE)
```

```
##  [1] "pretzels" "popcorn"  "carrots"  "carrots"  "bamba"    "popcorn" 
##  [7] "carrots"  "carrots"  "cookies"  "bamba"
```

---

# Sample probabilities


```r
sample(snacks, 10, replace = TRUE,
       prob = c(.8, .05, .05, .05, .05))
```

```
##  [1] "pretzels" "pretzels" "pretzels" "pretzels" "pretzels" "pretzels"
##  [7] "pretzels" "pretzels" "pretzels" "pretzels"
```

.center[.img-small[
![](img/pretzel.jpg)
]]

---

# Shortcut: use an integer instead of a vector


```r
sample(5)
```

```
## [1] 2 1 3 5 4
```

```r
sample(1:5)
```

```
## [1] 2 5 1 3 4
```

---
class: center, inverse, middle

# `?Distributions`
---

# Types of distributions

- **d**xxx - density/mass function
- **p**xxx - cumulative distribution function
- **q**xxx - quantile function
- **r**xxx - random generation

---

# Uniform distribution 


```r
*tibble(x = runif(1000)) %&gt;%
  ggplot(aes(x)) + geom_histogram(bins = 50)
```

&lt;img src="index_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;

---
# Normal distribution


```r
*tibble(x = rnorm(1000)) %&gt;%
  ggplot(aes(x)) + geom_histogram(bins = 50)
```

&lt;img src="index_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

---
# Binomial distribution


```r
*tibble(x = rbinom(1000, 1, prob = .7)) %&gt;%
  ggplot(aes(x)) + geom_histogram(bins = 50)
```

&lt;img src="index_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;

---
# Bootstrapping

.center[
![](https://wilkelab.org/ungeviz/articles/sampling-bootstrapping_files/figure-html/bootstrap-demo-1.gif)
]

[ungeviz](https://wilkelab.org/ungeviz/index.html) by Claus Wilke
---
class: middle, center, inverse

# Null models
---
# What are null models?

_A null model is a pattern generating model that is based on randomization of…data or random sampling from a known or imagined distribution. The null model is designed with respect to some ecological or evolutionary process of interest’._

.pull-left[
![](img/Null.png)
]

.pull-right[
Gotelli &amp; Graves 1996

_Null models in ecology_
]
---
# Why use them?

1) Assumptions of classical statistical tests are often not met.

2) Random processes may result in non-random patterns.

.center[
![](img/Mudkip.png)
]

---
# How to prepare your own null model in 5 easy steps!

.pull-left[
1) Collect data

2) Break the structure in the data by replacing process of interest with random draw

3) Repeat many, many, many times

4) Collate all the repetitions to generate a null distribution

5) Compare obaserved pattern to random pattern expected by chance
]

.bottom[
![](img/MarthaStewart.tif)
]
---
# Example:
Do grey Pokemon have higher defense values than other pokemon?

```r
pokemon &lt;- read_csv("data/pokemon.csv")
```

We can run a simple t-test to find out:

```r
pokemon &lt;- pokemon %&gt;%
    mutate(color2 = fct_collapse(
        color,
        Grey = c("Grey"),
        Not_grey = c("Black", "Blue", "Brown", "Green", "Pink", "Purple", "Red", "White", "Yellow")
    ))
```
---

```r
t.test(defense ~ color2, pokemon)
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  defense by color2
## t = -4.5122, df = 75.696, p-value = 2.31e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -30.59050 -11.85429
## sample estimates:
## mean in group Not_grey     mean in group Grey 
##               68.77761               90.00000
```
The answer is: yes, they do.
---
# Now let's do the same thing but with a null model instead!
1) A numeric value: how many observations are in our group of interest?

```r
n &lt;- length(which(pokemon$color2 == "Grey"))
```
2) A vector containing the pooled observations.

```r
x &lt;- pokemon$defense
```
3) An empty vector in the length of however many iterations we want to run.

```r
t &lt;- vector(length = 10000)
```
---
4) This is our null model - for each iteration, we randomly sample n values out of x, without replacements. This gives us a simulated "grey" group, where pokemon are assigned randomly. We then calculate a t-score for that group. After running this process for t iterations, we get a null distribution of t-scores.

```r
for (i in 1:length(t)){
    grey &lt;- sample(x, n, replace = F)
    not_grey &lt;- setdiff(x, grey)
    t[i] &lt;- (mean(grey) - mean(not_grey)) / (sqrt(var(grey)/length(grey)))
}
```
---
Now that we have a null distribution, we can calculate the observed t-score:

```r
pokemon_sum &lt;- pokemon %&gt;%
    group_by(color2) %&gt;%
    summarise(
        mean = mean(defense),
        se = sqrt(var(defense))/n()
    )
obs &lt;- (pokemon_sum[2,2] - pokemon_sum[1,2])/pokemon_sum[2,3]
```
And of course, a p-value.
This is calculated as the precentage of t-scores in the null distribution as extreme, or more extreme, than the observed t-score.

```r
p.val&lt;-(length(which(abs(t) &gt;= abs(as.numeric(obs)))) / length(t))
p.val
```

```
## [1] 0
```
---
Now let's visualize this. We'll plot the histogram of the null distribution, and mark our observed value with a red line: We can see here very clearly that our observed t-score is very, very extreme.

```r
data_frame(scores = t, obs = obs$mean) %&gt;%
    ggplot() +
    geom_density(aes(scores)) + 
    geom_vline(xintercept = obs[[1]], color = "red")
```

&lt;img src="index_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;
---

Now we can start adding complications. For instance, you may recall that _grey_ Pokemon tend to be _steel_ type.

.center[
![](img/Steelix.png)
![](img/Skarmory.png)
]
So how do we incorporate this into our null model?
---
# Weighted sampling
One of the things we can do is to make sure, when we construct our model, to make the sampling from the pool not random, but weighted according to another variable.

In this case, we would give a higher probability to selecting a steel type Pokemon when generating our "grey" group.
How much higher?

For this example we can base it on the distribution of types of *all* grey Pokemon, to make sure our simulated "grey" group has a similar distribution of types as our observed group.
---

```r
chi_data &lt;- table(pokemon$type_1, pokemon$color2)
grey_prop &lt;- tibble(
    type_1 = row.names(chi_data),
    prop = chi_data[,2]/sum(chi_data[,2])
)
grey_prop
```

```
## # A tibble: 18 x 2
##    type_1     prop
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 Bug      0.116 
##  2 Dark     0.0580
##  3 Dragon   0.0145
##  4 Electric 0.0435
##  5 Fairy    0     
##  6 Fighting 0.0870
##  7 Fire     0     
##  8 Flying   0     
##  9 Ghost    0     
## 10 Grass    0.0435
## 11 Ground   0.0870
## 12 Ice      0.0290
## 13 Normal   0.145 
## 14 Poison   0     
## 15 Psychic  0.0290
## 16 Rock     0.145 
## 17 Steel    0.145 
## 18 Water    0.0580
```
---

```r
pokemon &lt;- merge(grey_prop, pokemon, by = "type_1")

n &lt;- length(which(pokemon$color2 == "Grey"))
x &lt;- pokemon$defense
t2 &lt;- vector(length = 10000)
prop &lt;- pokemon$prop

for (i in 1:length(t)){
    grey &lt;- sample(x,
                   n,
                   replace = F,
                   prob = prop)
    not_grey &lt;- setdiff(x, grey)
    t2[i] &lt;- (mean(grey) - mean(not_grey)) / (sqrt(var(grey)/length(grey)))
}
```
---

```r
pokemon_sum &lt;- pokemon %&gt;%
    group_by(color2) %&gt;%
    summarise(
        mean = mean(defense),
        se = sqrt(var(defense))/n()
    )
obs &lt;- (pokemon_sum[2,2] - pokemon_sum[1,2])/pokemon_sum[2,3]

p.val&lt;-(length(which(abs(t2) &gt;= abs(as.numeric(obs)))) / length(t2))
p.val
```

```
## [1] 0
```
---

```r
tibble(scores = t2, obs = obs$mean) %&gt;%
    ggplot() +
    geom_density(aes(scores)) + 
    geom_vline(xintercept = obs[[1]], color = "red")
```

&lt;img src="index_files/figure-html/unnamed-chunk-23-1.png" style="display: block; margin: auto;" /&gt;
In this case the results are basically the same, still a significant difference.
---
But if we look more closely, we can see that the null distributions actually differ slightly from one another:

```r
tibble(random = t, weighted = t2) %&gt;%
    gather("model", "scores") %&gt;%
    ggdensity(x = "scores",
              fill = "model")
```

&lt;img src="index_files/figure-html/unnamed-chunk-24-1.png" style="display: block; margin: auto;" /&gt;
---
# Biases:

There are two main issues that can occur when constructing null models, and we should always be aware of them:

.bottom[
![](img/frustration.jpg)
]
---

# 1) Narcissus effect
### (Colwell &amp; Winkler 1984)

.pull-left[
The null model algorithm includes the effect it was trying to omit.

##INFLATED TYPE II ERROR RATE!

_'Narcissus could not see the bottom of the pool for his own image, and could not guess its depth.'_
]

.bottom-right[
![](img/narcissus.jpg)
]
---
#2) Jack Horner effect
### (Wilson 1995)

.pull-left[
The null model algorithm omits effects it shouldn't.

##INFLATED TYPE I ERROR RATE!

_'Jack Horner...thought himself a good boy for demonstrating that plum pies contain plums.'_

]

.bottom-right[
![](img/jackhorner.jpg)
]
---
# Take home

Null models are powerful!!!

1) They can be tailor-made to fit any type of data/question;

2) They require _zero_ assumptions about the underlying structure of the data;

But you have to use your brain, even more than usual!

.bottom-right[
![](img/Psyduck.png)
]

---

# Cross-validation!

Cross-validation is a useful tool to test how good your model is. How?

1) Divide your data into a training set and a test (validation) set. _This is where randomization is important!_

2) Build your model using the training set.

3) Test your model predictions on the test set!

_A good model will give good predictions on the testing set._

---

# There are many different methods for cross-validation.

Many rely on randomly sampling part of your data to divide it into a training and test set, and repeating the process many times to eventually average the measure of how good the model is across all iteration.

##Sounds familiar?

.bottom-right[
.img-small[
![](img/Ditto.png)
]
]
---


```r
library(caret)
```

We are going to be using this package for our cross-validation purposes, although it's useful for many other things to do with predictive modeling, and it interfaces with a ton of other packages.

Look into it:
http://topepo.github.io/caret/

.bottom-right[
![](img/Trainer.png)
]

---
class: exercise

# Exercise

Which model best predicts the relationship between _attack_ and _special defense_ scores of Pokemon?

.center[
![](img/Mewtwo.png)
![](img/Shuckle.png)
]

---

Let's begin with a scatterplot:

```r
pokemon %&gt;% 
    ggplot(aes(attack, sp_def)) +
    geom_point()
```

&lt;img src="index_files/figure-html/unnamed-chunk-26-1.png" style="display: block; margin: auto;" /&gt;

---

We can see that there is a somewhat linear relationship between the two variables. So we can try to fit three types of models:

1) a linear model.

1.5) a linear model with a quadratic term.

2) a general additive model with loess smoothing.

---


```r
model1 &lt;- lm(sp_def ~ attack, data = pokemon)
pokemon %&gt;% 
    ggplot(aes(attack, sp_def)) +
    geom_point() +
    geom_smooth(method = "lm")
```

&lt;img src="index_files/figure-html/unnamed-chunk-27-1.png" style="display: block; margin: auto;" /&gt;

---


```r
model1.5 &lt;- lm(sp_def ~ I(attack^2), data = pokemon)
pokemon %&gt;% 
    ggplot(aes(attack, sp_def)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ I(x^2))
```

&lt;img src="index_files/figure-html/unnamed-chunk-28-1.png" style="display: block; margin: auto;" /&gt;

---


```r
model2 &lt;- gam(sp_def ~ lo(attack), data = pokemon)
pokemon %&gt;% 
    ggplot(aes(attack, sp_def)) +
    geom_point() +
    geom_smooth(method = "loess")
```

&lt;img src="index_files/figure-html/unnamed-chunk-29-1.png" style="display: block; margin: auto;" /&gt;

---
class: inverse, middle, center

###Which model is better?

---

# k-folds cross-validation

1) Randomly split your entire dataset into _k_ ”folds”.

2) For each _k_-fold, build your model on _k_ – 1 folds of the dataset. Then, test the model on the _k_ th fold.

3) Save the error of the model for each _k_-fold.

4) Repeat until each of the _k_-folds has served as the test set.

5) The average of the _k_ errors is  the &lt;b&gt;cross-validation error&lt;/b&gt; - the lower this value is, the better your model.

---

# k-folds cross-validation

.center[
![](img/kfolds.jpg)
]

---


```r
train_control &lt;- trainControl(method="cv", number=10)
```

This function determines how we create training sets.

_method_ determines which method to use. "cv" gives us k-folds cross-validation, and _number_ determines how many _k_ folds we choose.

&lt;b&gt;Selecting the correct _k_ is not trivial at all, and will affect your results!&lt;/b&gt; For now let's use 10.

.center[
![](img/UnownK.png)
]
---


```r
model1 &lt;- train(sp_def ~ attack,
                data = pokemon,
                trControl = train_control,
                method = "lm")

model1.5 &lt;- train(sp_def ~ I(attack^2),
                  data = pokemon,
                  trControl = train_control,
                  method = "lm")

model2 &lt;- train(sp_def ~ attack,
                data = pokemon,
                trControl = train_control,
                method = "gamLoess")
```

_train_ is the function to actually run the cross-validation process, using the control parameters we set up with _trainControl_.

_method_ determines the model we use - there are many!

---


```r
model1
```

```
## Linear Regression 
## 
## 721 samples
##   1 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 648, 650, 648, 648, 648, 648, ... 
## Resampling results:
## 
##   RMSE      Rsquared    MAE     
##   26.35148  0.06018275  20.21779
## 
## Tuning parameter 'intercept' was held constant at a value of TRUE
```

---


```r
model1.5
```

```
## Linear Regression 
## 
## 721 samples
##   1 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 648, 648, 649, 649, 650, 649, ... 
## Resampling results:
## 
##   RMSE     Rsquared    MAE     
##   26.3821  0.06155288  20.30365
## 
## Tuning parameter 'intercept' was held constant at a value of TRUE
```

---


```r
model2
```

```
## Generalized Additive Model using LOESS 
## 
## 721 samples
##   1 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 648, 650, 649, 648, 648, 651, ... 
## Resampling results:
## 
##   RMSE      Rsquared    MAE    
##   26.31513  0.06250771  20.2172
## 
## Tuning parameter 'span' was held constant at a value of 0.5
## 
## Tuning parameter 'degree' was held constant at a value of 1
```

---

We choose the model with the lowest average error across all _k_ iterations - in this case, &lt;b&gt;model2&lt;/b&gt; with an average RMSE of _26.31513_.

Out of our three options, this model performed best in the cross-validation process.

.right[
![](img/Spheal.png)
]
---

# Take home

Cross-validation can be useful. &lt;b&gt;Use it!&lt;/b&gt;

.center[
![](img/Leg.png)
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
